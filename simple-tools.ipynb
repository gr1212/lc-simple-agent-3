{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain demo\n",
    "\n",
    "## Links\n",
    "1. [samwit - colab - YT LangChain - Agents.ipynb, React & Serpai ](https://colab.research.google.com/drive/1QpvUHQzpHPvlMgBElwd5NJQ6qpryVeWE?usp=sharing)\n",
    "1. [samwit - github youtube samples](https://github.com/samwit/langchain-tutorials/tree/main)\n",
    "1. [Building Custom Tools and Agents with LangChain (gpt-3.5-turbo)](https://www.youtube.com/watch?v=biS8G8x8DdA): [samwit - colab - YT LangChain Custom Tools & Agents.ipynb](https://colab.research.google.com/drive/1FYsa3x3PzziL57EHEIuIqa5rkCAxCbin?usp=sharing) uses chat-conversational-react-description\n",
    "\n",
    "## Demo use case\n",
    "\n",
    "### Tools\n",
    "1. IncidentTool. Simple text\n",
    "1. KnowledgeBaseTool: Vectorstore \n",
    "1. NewRelicTool: PandasAI\n",
    "1. OrgSearchTool: Team, people, rules of engagement\n",
    "\n",
    "### Flow\n",
    "1. Get inc\n",
    "1. Describe steps for user to create/trigger\n",
    "    1. Narrative\n",
    "    1. Bullet point flow\n",
    "1. Describe what happened\n",
    "    1. Narrative\n",
    "    1. Bullet point flow\n",
    "1. Team to direct inc to\n",
    "    1. Team/person\n",
    "    1. How to engage (i.e., email, Absa Snow with configs)\n",
    "1. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Load setting from Json outside of project.\n",
    "f = open('../../env/ai.json')\n",
    "settingsJson = json.load(f)\n",
    "\n",
    "for key in settingsJson:\n",
    "    os.environ[key] = settingsJson[key]\n",
    "    \n",
    "# # OR manually set them\n",
    "# os.environ['REQUESTS_CA_BUNDLE'] = '../../env/ZCert.pem'\n",
    "# os.environ['HUGGING_FACE_API_KEY'] = 'Get here: https://huggingface.co/settings/tokens'\n",
    "# os.environ['OPENAI_API_KEY'] = 'Get here: https://platform.openai.com/account/api-keys'\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = 'serpapi KEY, Get here: https://serpapi.com/manage-api-key'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install langchain huggingface_hub openai google-search-results tiktoken wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Text Tool\n",
    "Returns simple text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Text Tool\n",
    "\n",
    "def incident_search(incident_number: str):\n",
    "    f = open('data/incident-store.txt')\n",
    "    with open('data/incident-store.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    return  lines\n",
    "\n",
    "incident_search_tool = Tool(\n",
    "    name='Incident tool', \n",
    "    func= incident_search,    \n",
    "    description=\"\"\"\n",
    "        Useful for queries about incidents.         \n",
    "        Use the date to order incidents.\n",
    "        The 'State' of an incident is 'Open' when the State field is not 'Resolved', 'Closed', 'Cancelled'        \n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstore \n",
    "Vectorstore\n",
    "https://python.langchain.com/docs/integrations/toolkits/vectorstore \\\n",
    "\\\n",
    "Markdown \\\n",
    "Try this later on \\\n",
    "https://python.langchain.com/docs/modules/data_connection/document_loaders/markdown \\\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/markdown_header_metadata \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install unstructured\n",
    "# I had issues here so ran the following to make PC trust PIP\n",
    "# pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pip setuptools\n",
    "# pip config set global.trusted-host \"pypi.org files.pythonhosted.org pypi.python.org\"\n",
    "\n",
    "#!pip install markdown\n",
    "#!pip install urllib3==1.25.11\n",
    "\n",
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/knowledge-base.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# loader = PyPDFLoader(\"data/south-africa-sarb-currency-and-exchanges-guidelines-for-business-entities.pdf\")\n",
    "# pages.append(loader.load_and_split())\n",
    "\n",
    "# loader = PyPDFLoader(\"data/south-africa-sarb-currency-and-exchanges-guidelines-for-business-entities.pdf\")\n",
    "# pages.append(loader.load_and_split())\n",
    "\n",
    "# south-africa-currency-and-exchanges-manual-for-authorised-dealers.pdf\n",
    "\n",
    "# for i in pages:\n",
    "#     print(i)\n",
    "#     print('**************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb\n",
    "# For chromadb you have to have C++ builders intalled see link below: \"I have faced similar issue on Windows OS, while doing...\"\n",
    "#   https://stackoverflow.com/questions/73969269/error-could-not-build-wheels-for-hnswlib-which-is-required-to-install-pyprojec\n",
    "\n",
    "#!pip install pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 80, in __init__\n",
      "    import chromadb\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\chromadb\\__init__.py\", line 4, in <module>\n",
      "    import chromadb.config\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\chromadb\\config.py\", line 12, in <module>\n",
      "    from pydantic import BaseSettings, validator\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\pydantic\\__init__.py\", line 210, in __getattr__\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\pydantic\\_migration.py\", line 289, in wrapper\n",
      "pydantic.errors.PydanticImportError: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.3/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.3/u/import-error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\abgr215\\AppData\\Local\\Temp\\ipykernel_14120\\2826984587.py\", line 6, in <module>\n",
      "    knowledgeStore = Chroma.from_documents(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 612, in from_documents\n",
      "    return cls.from_texts(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 567, in from_texts\n",
      "    chroma_collection = cls(\n",
      "                        ^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 83, in __init__\n",
      "    raise ImportError(\n",
      "ImportError: Could not import chromadb python package. Please install it with `pip install chromadb`.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\sc\\ai\\lc-simple-agent-3\\.venv\\Lib\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# print(pages[0])\n",
    "knowledgeStore = Chroma.from_documents(\n",
    "    pages, embeddings, collection_name=\"knowledge-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "page_content='Heading 1\\n\\nabc\\n\\nHeading 2\\n\\nefg\\n\\nHeading 3\\n\\nhij\\n\\nHeading 4\\n\\nklm' metadata={'source': 'data/test.md'}\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "import markdown\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
    "\n",
    "#loader = UnstructuredMarkdownLoader(\"data/knowledge-base.md\")\n",
    "loader = UnstructuredMarkdownLoader(\"data/test.md\")\n",
    "documents = loader.load()\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))\n",
    "for i in texts:\n",
    "    print(i)\n",
    "    print('**************************')\n",
    "# print(texts[0])\n",
    "# print('********************************')\n",
    "# print(texts[1])\n",
    "# print('********************************')\n",
    "# print(texts[2])\n",
    "# print('********************************')\n",
    "# print(texts[3])\n",
    "# print('********************************')\n",
    "# print(texts[4])\n",
    "# print('********************************')\n",
    "# print(texts[5])\n",
    "# print('********************************')\n",
    "# print(texts[6])\n",
    "\n",
    "# # https://python.langchain.com/docs/integrations/vectorstores/starrocks\n",
    "# loader = DirectoryLoader(\n",
    "#     \"./data\", glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader\n",
    "# )\n",
    "# documents = loader.load()\n",
    "\n",
    "# # load text splitter and split docs into snippets of text\n",
    "# text_splitter = TokenTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "# # split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# # tell vectordb to update text embeddings\n",
    "# #update_vectordb = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain.text_splitter import (\n",
    "#     RecursiveCharacterTextSplitter,\n",
    "#     Language,\n",
    "# )\n",
    "\n",
    "# loader = UnstructuredMarkdownLoader(\"data/knowledge-base.md\")\n",
    "# documents = loader.load()\n",
    "# # print(type(documents[0]))\n",
    "# # print(documents[0])\n",
    "\n",
    "# # https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter#markdown\n",
    "# md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "#     language=Language.MARKDOWN, chunk_size=60, chunk_overlap=0\n",
    "# )\n",
    "\n",
    "# md_docs = md_splitter.create_documents([documents])\n",
    "\n",
    "# md_docs = md_splitter.create_documents([markdown_text])\n",
    "# md_docs\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# state_of_union_store = Chroma.from_documents(\n",
    "#     texts, embeddings, collection_name=\"state-of-union\"\n",
    "# )\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# from langchain.document_loaders import TextLoader\n",
    "\n",
    "# loader = TextLoader(\"../../../state_of_the_union.txt\")\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# state_of_union_store = Chroma.from_documents(\n",
    "#     texts, embeddings, collection_name=\"state-of-union\"\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "tools = [incident_search_tool]\n",
    "\n",
    "#del memory \n",
    "\n",
    "# conversational agent memory\n",
    "memory = ConversationBufferWindowMemory(memory_key='chat_history', k=3, return_messages=True)\n",
    "\n",
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
    "\n",
    "# create our agent\n",
    "conversational_agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=turbo_llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Incident tool\",\n",
      "    \"action_input\": \"application crash when clicking detach\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['INC123\\n', 'Short Description: Rates not available\\n', 'Date: 2023-08-20:  \\n', 'Description: Rates are not ticking for USD/UG3/SP. Please investigate\\n', 'State: Closed\\n', 'Issue: All cross pair rates for TD or tenor 20230901 are not available from upstream due to an issue in the Static Data Store Service\\n', 'Customer Impact: From 2023-08-20 start of day until 11:35 all clients would not have been able to get any rates or book deals for any cross pairs (all non-USD pairs like EURZAR) for the tenor TD or broken date 20230901.\\n', 'Root Cause: A bug was found in Static Data Store Service which was triggered by the US holiday on 20230904 which caused rates to fail for 20230901.\\n', 'Root Cause Fix: N/A - FX Data Team is still investigating.\\n', 'Runbook: Rates Error Mapping Runbook\\n', 'Mitigation fix: Pricing Service has switched over to the 360T fallback feed until the issue in Static Data Store Service is resolved.\\n', '\\n', 'INC456\\n', 'Short Description: User at CorpA not getting OTP\\n', 'Date: 2023-09-21:  \\n', 'Description: Mary Sue at CorpA is not getting on OTP when she tries to login\\n', 'State: On Hold\\n', 'Notes:\\n', '        2023-09-21 13:00: @SupportMember1 reached out to the communication delivery team to ask what if there are issues, waiting on feedback.\\n', '        \\n', 'INC789\\n', 'Short Description: Application keeps crashing\\n', 'Date: 2023-07-21:  \\n', 'Description: Bob Jons at MegaCorpB has the app crashing when he clicks on detach. \\n', 'State: In Progress\\n', 'Notes:\\n', '        2023-09-21 09:30: @SupportMember2 sent email to customer and waiting for feedback from the customer about setting up a call to try and see what is going on.\\n', '        2023-09-21 10:30: @SupportMember2 had call with the customer, there were some windows updates pending. They are going to do these updates after work today and feedback\\n']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Based on the incident logs, there was a previous incident (INC789) reported on 2023-07-21 where a user at MegaCorpB experienced application crashes when clicking on detach. The incident is currently in progress, and the support team has reached out to the customer for further investigation. It is recommended to check if there are any pending Windows updates on the user's machine and perform them after work today. If the issue persists, further investigation may be required.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"\\nYou are a support engineer who is helping troubleshoot software issues. \\nYou responses need to be specific and factful, they can only contain information that you get back from the tools and observations.\\nIf you don't know the answer then say so and don't make up anything. \\n\\nQuestion: How do I troubleshoot a user who's application keeps crashing when they click detach?\\n\", 'chat_history': [], 'output': \"Based on the incident logs, there was a previous incident (INC789) reported on 2023-07-21 where a user at MegaCorpB experienced application crashes when clicking on detach. The incident is currently in progress, and the support team has reached out to the customer for further investigation. It is recommended to check if there are any pending Windows updates on the user's machine and perform them after work today. If the issue persists, further investigation may be required.\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "You are a support engineer who is helping troubleshoot software issues. \n",
    "You responses need to be specific and factful, they can only contain information that you get back from the tools and observations.\n",
    "If you don't know the answer then say so and don't make up anything. \n",
    "\n",
    "Question: How do I troubleshoot a user who's application keeps crashing when they click detach?\n",
    "\"\"\"\n",
    "# Question: What did the user do to create the latest incident?\n",
    "\n",
    "answer = conversational_agent(question)\n",
    "print(answer)\n",
    "x = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5e69aaaff91c6807e0ef15afd464516a5dabc9ed5ae56c263ce858cc6c8715f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
